{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf197ce-19bc-4c42-8bb0-b4ea967cd832",
   "metadata": {},
   "source": [
    "### Objective: \n",
    "This notebook provides an overview on how to use the framework for Prompt tracking. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b557b-b349-432e-88af-619e0a0dc646",
   "metadata": {},
   "source": [
    "#### AI/ ML engineer journey on Prompt Engineering\n",
    "```\n",
    "AI Engineer\n",
    "     |\n",
    "     v\n",
    "Create Experiment (\"prompts for Text2SQL\")\n",
    "     |\n",
    "     v\n",
    "+-------------------------+        +--------------+        +----------------------+\n",
    "|   Run 1: LLM model      | -----> | Check result | -----> | F1 score(metric): 0.81|\n",
    "| name=gemini-1.5-flash,\n",
    " temperature=0.1          |         +--------------+        +----------------------+\n",
    "+-------------------------+\n",
    "\n",
    "     |\n",
    "     v\n",
    "\n",
    "+-------------------------+        +--------------+        +----------------------+\n",
    "|   Run 2: LLM model      | -----> | Check result | -----> | F1 score(metric): 0.85|\n",
    "| name=gemini-1.5-pro,\n",
    " temperature=0.1          |        +--------------+        +-----------------------+\n",
    "+-------------------------+\n",
    "\n",
    "     |\n",
    "     v\n",
    "\n",
    "More Runs (optional)\n",
    "     |\n",
    "     v\n",
    "Compare & Analyze Results\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25215506-dd01-4f07-a813-91536ef5d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import pacakges\n",
    "from src import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672de0ae-2f4e-4013-b09d-799d483e9886",
   "metadata": {},
   "source": [
    "#### Create the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e27de44-a63d-41d0-bf01-23879cb8b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project TEXT2SQL - (ID: 8391b544-247a-497b-acfb-43694fda3762) created successfully\n"
     ]
    }
   ],
   "source": [
    "tree.set_project(name = \"TEXT2SQL\",\n",
    "                 created_by = \"member 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5414c0-7ebf-405f-865d-ba3ca700378c",
   "metadata": {},
   "source": [
    "#### Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9174d668-4080-4ef0-b48e-d9808e63d1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment text2sql_simple_prompting - (ID: 33d83978-f23b-40fb-a544-7000eda2c0e3) created successfully\n"
     ]
    }
   ],
   "source": [
    "tree.set_experiment(name = \"text2sql_simple_prompting\",\n",
    "                 created_by = \"member 1\",\n",
    "                 description = \"Apply direct prompting for text2sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ab26b-c8f8-449f-a300-2a2fe78a750f",
   "metadata": {},
   "source": [
    "#### Start Runs\n",
    "A run is an instance of the experiment with specific hyperparamters and other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff46092-0115-41a3-b428-210815969016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run run1 - (ID: 80b5224f-dc10-40be-8883-fc4dafbeb69d) created successfully\n"
     ]
    }
   ],
   "source": [
    "tree.start_run(name=\"run1\", created_by=\"member 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb29d7-d24f-4964-a070-45b408ca7119",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb06f43-d738-446c-a42e-cdfee148d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an expert in generating SQL queries from english text. Given below is text to convert to SQL \\n\n",
    "get me all rows with name XYZ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b93dc56-c2e8-488a-aa96-ebb95a9ed28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'prompt : direct_prompting' logged (ID: 48d14691-eec4-4f6b-9d62-e4d2902ef512)\n"
     ]
    }
   ],
   "source": [
    "tree.log_prompts(name=\"direct_prompting\", value=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c5757f-1b9e-4ec4-b981-dda5ba56aba2",
   "metadata": {},
   "source": [
    "#### Perform training with hyperparameters and log the experiment metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5005832-86ec-4584-9b0c-05b74c301ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hyperparameter : model' logged (ID: cbadcf65-781c-41f8-a07b-a33bbcaecaa5)\n",
      "'hyperparameter : temperature' logged (ID: fd36a53c-942f-47cc-b116-32fa358900e4)\n",
      "'hyperparameter : random_state' logged (ID: 323fdc63-507e-4908-96e2-0b9ee998daf3)\n"
     ]
    }
   ],
   "source": [
    "llm_params = {\n",
    "    \"model\": \"gemini-1.5-flash\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "tree.log_hyperparameters(value = llm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c8d1f8-bea8-4e95-b1f4-baf5668de45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM():\n",
    "    ## dummy LLM - replace with actual model api/code\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def invoke(self, query):\n",
    "        return \"SELECT * FROM your_table_name WHERE name = XYZ\"\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88ff2a3-90c7-43b1-9662-94b2155c3fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLM(llm_params)\n",
    "result = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4187242d-acd5-4627-a213-eb6790b6678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'metric : F1 score' logged (ID: 84c55e65-9698-437f-a2e3-83805951df55)\n",
      "'artifact : output' logged (ID: 06a921a8-2ddc-4bc8-80d3-aac320e9721f)\n"
     ]
    }
   ],
   "source": [
    "# evaluate -  setting dummy value\n",
    "tree.log_metrics(name=\"F1 score\", \n",
    "                 value = 0.81)\n",
    "\n",
    "#log result as artifact\n",
    "tree.log_artifacts(name=\"output\", value=result, artifact_type=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ef5a4-8c8f-48f5-859a-2b47f82f0571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9cbb50a-8097-412b-a53a-b3e617ee139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54ee1d-4b12-4db0-aa14-227b500c55be",
   "metadata": {},
   "source": [
    "#### Train with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c222fa3e-850e-41f3-989f-3955b14132c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run run2 - (ID: 85926484-86f1-4a6c-bb37-5a904cb1c011) created successfully\n"
     ]
    }
   ],
   "source": [
    "tree.start_run(name=\"run2\", created_by=\"member 1\") #create a new run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4218ed85-221d-42d3-8aa9-1ddf22f46de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hyperparameter : model' logged (ID: c0dc671f-8d7b-416b-b7d6-20ae82782f2e)\n",
      "'hyperparameter : temperature' logged (ID: dab15d95-92b5-4b4b-81c3-31e9148001e9)\n",
      "'hyperparameter : random_state' logged (ID: ed2c0f9e-996a-4917-91cd-bbe16bac8eae)\n"
     ]
    }
   ],
   "source": [
    "llm_params = {\n",
    "    \"model\": \"gemini-1.5-pro\",\n",
    "    \"temperature\": 0.2,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "tree.log_hyperparameters(value = llm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67f1965c-4df7-4db5-8bbb-398cdafb36ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'prompt : direct_prompting' logged (ID: 52df9319-3cd1-4666-9eee-cfc14de02105)\n",
      "'metric : F1 score' logged (ID: c95b61cf-c699-4921-ab67-6e86420d3d5c)\n",
      "'artifact : output' logged (ID: df9b4372-d300-416f-b30c-4671bb1aa412)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Given below is a text to be converted to SQL. You can do this because you are a data engineer \\n\n",
    "get me all rows with name XYZ\"\"\"\n",
    "\n",
    "tree.log_prompts(name=\"direct_prompting\", value=prompt)\n",
    "\n",
    "model = LLM(llm_params)\n",
    "result = model.invoke(prompt)\n",
    "\n",
    "# evaluate -  setting dummy value\n",
    "tree.log_metrics(name=\"F1 score\", \n",
    "                 value = 0.85)\n",
    "\n",
    "#log result as artifact\n",
    "tree.log_artifacts(name=\"output\", value=\"SELECT * FROM your_table_name WHERE name = 'XYZ'\", artifact_type=\"data\")\n",
    "\n",
    "tree.stop_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583a9f6-3ea1-40da-82ce-fb38c93947b0",
   "metadata": {},
   "source": [
    "#### Explore Experiment and compare Runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bdb61d0-f69d-4e6c-b3a6-410c5a735090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e009461960450e89e717be61bc96d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h1 style='color: #2c3e50; margin-bottom: 20px;'>Experiment Dashboard</h1>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4872239764041c7b43d5a343f82e974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Experiment:', layout=Layout(width='350px'), options=('text2sql_simple_prompting',), styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca16c3ad7964c3e996007ae9abb301a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n        <div style='border: 1px solid #e0e0e0; border-radius: 8px; padding: 15px; margin-bottom:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7451ab43d6b426c8feb203a0a8b5cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-size: 1.3em; font-weight: bold; color: #3a3a3a; margin-bottom: 12px;'>Metrics Sum…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cec510b65cf445593771f923d87f45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Filter runs:', layout=Layout(margin='0 20px 0 0', width='350px'), p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deddced14fd04eec803b69a9881efe0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value=\"<div style='font-size: 1.3em; font-weight: bold; color: #3a3a3a; mar…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7969996da24ef985d7e12035ecf4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='padding: 8px; color: #555;'>Displaying 2 runs for experiment 'text2sql_simple_promptin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.view_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d476ab-74fd-402d-a114-f89a8b7b0781",
   "metadata": {},
   "source": [
    "#### Look at individual runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "353476b7-58a7-454e-abc6-9357bc8756ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62399520c3a042a79e44a1b23d619593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n        <style>\\n            .run-view-container { max-width: 1000px; margin: 0 auto; font-famil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc657b8380024ab7b07333b1a3a539c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<div class=\"run-view-header\"><div class=\"run-view-title\">ML Run Explorer</div></div…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.view_runs(experiment_name=\"text2sql_simple_prompting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b39d2-9e22-4509-ab36-f0be63bd9ff7",
   "metadata": {},
   "source": [
    "#### Export tree and track this file on git - experiment metadata can be tracked on git like any other code/file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59dd344a-820e-4fe1-9426-92c796adb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_tree(filename=\"prompt_text2sql.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
